#If you wish to add your own custom analyzers to elasticsearch
#modify this file.  The template shown below is what we use in our
#application
settings:
  analysis:
    analyzer:
      english_to_korean_synonym:
        tokenizer: "standard"
        filter:
          - "synonym"
          - "english_possessive_stemmer"
          - "lowercase"
          - "english_stop"
          - "english_keywords"
          - "english_stemmer"
      english_edge:
        tokenizer: "english_edge_tokenizer"
        filter:
          - "english_possessive_stemmer"
          - "lowercase"
          - "english_stop"
          - "english_keywords"
          - "english_stemmer"
          - "name_edge_stop"
    tokenizer:
      english_edge_tokenizer:
        type: "edgeNGram"
        min_gram: 3
        max_gram: 10
        token_chars:
          - "letter"
          - "digit"
    filter:
      english_stop:
        type: "stop"
        stopwords: "_english_"
      english_keywords:
        type: "keyword_marker"
        keywords: "keywords"
      english_stemmer:
        type: "stemmer"
        language: "english"
      english_possessive_stemmer:
        type: "stemmer"
        language: "possessive_english"
      synonym:
        type: "synonym"
        synonyms_path: "analysis/synonyms.txt"
      name_edge_stop:
        type: "stop"
        stopwords_path: "analysis/stopwords.txt"

